{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "movie review classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishnu3983/Movie-review-classification/blob/master/movie_review_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "smHdtJYNmc_2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aIaa3OmZmpX3",
        "colab_type": "code",
        "outputId": "99428e41-03ca-4462-a866-228650a2f75f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "imdb = keras.datasets.imdb\n",
        "top_words = 10000\n",
        "max_len = 500\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=top_words)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tj0f4EA1m7mB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
        "                                                        maxlen=max_len)\n",
        "\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
        "                                                       maxlen=max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QRZ2YkWyskRW",
        "colab_type": "code",
        "outputId": "0056472f-cd3f-46ac-82ea-99d14f5479ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# MLP for the IMDB problem\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Xjat8GE0orNP",
        "colab_type": "code",
        "outputId": "01f0daba-43f9-4157-f3b0-8f56d480a330",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "# create the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(top_words, 32, input_length=max_len))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(250, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 500, 32)           320000    \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 16000)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 250)               4000250   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 251       \n",
            "=================================================================\n",
            "Total params: 4,320,501\n",
            "Trainable params: 4,320,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VYpN7JIYtZsI",
        "colab_type": "code",
        "outputId": "3bd34aca-41ea-4e3c-98df-60da2849e997",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model.fit(train_data, train_labels, validation_data=(test_data, test_labels), epochs=2, batch_size=128)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(test_data, test_labels)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/2\n",
            "25000/25000 [==============================] - 6s 225us/step - loss: 0.4405 - acc: 0.7688 - val_loss: 0.2851 - val_acc: 0.8811\n",
            "Epoch 2/2\n",
            "25000/25000 [==============================] - 3s 132us/step - loss: 0.1321 - acc: 0.9541 - val_loss: 0.3301 - val_acc: 0.8674\n",
            "25000/25000 [==============================] - 2s 64us/step\n",
            "Accuracy: 86.74%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Hj6gD8ONwC56",
        "colab_type": "code",
        "outputId": "1834b553-3f48-4d1b-8f87-23d9b38b59dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import LSTM\n",
        "model2 = Sequential() \n",
        "model2.add(Embedding(top_words, 32, input_length=max_len)) \n",
        "model2.add(LSTM(100)) \n",
        "model2.add(Dense(1, activation='sigmoid')) \n",
        "model2.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy']) \n",
        "print(model2.summary())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 500, 32)           320000    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 373,301\n",
            "Trainable params: 373,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XUi4inUnwkb0",
        "colab_type": "code",
        "outputId": "f83eba0b-10c7-4250-8906-5e6207cc9953",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "model2.fit(train_data, train_labels, validation_data=(test_data, test_labels), epochs=3, batch_size=64)\n",
        "scores = model2.evaluate(test_data, test_labels, verbose=0) \n",
        "\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/3\n",
            "25000/25000 [==============================] - 663s 27ms/step - loss: 0.4609 - acc: 0.7732 - val_loss: 0.5356 - val_acc: 0.7265\n",
            "Epoch 2/3\n",
            "25000/25000 [==============================] - 656s 26ms/step - loss: 0.2846 - acc: 0.8862 - val_loss: 0.3183 - val_acc: 0.8654\n",
            "Epoch 3/3\n",
            "25000/25000 [==============================] - 661s 26ms/step - loss: 0.2215 - acc: 0.9161 - val_loss: 0.3177 - val_acc: 0.8703\n",
            "Accuracy: 87.03%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jsRuoY7mRl-U",
        "colab_type": "code",
        "outputId": "90719ebf-35e9-4a29-b03b-8760f8c97153",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#short bad review\n",
        "review=\"The movie was a disaster. It was bad\"\n",
        "\n",
        "tmp=[]\n",
        "word_to_id = keras.datasets.imdb.get_word_index()\n",
        "\n",
        "review = review.lower()\n",
        "review = review.replace('.', '')\n",
        "\n",
        "for word in review.split(\" \"):\n",
        "  try:\n",
        "    (word_to_id[word])\n",
        "    tmp.append(word_to_id[word])\n",
        "  except:\n",
        "    tmp.append(0)\n",
        "    \n",
        "check = keras.preprocessing.sequence.pad_sequences([tmp],\n",
        "                                                        maxlen=max_len)\n",
        "\n",
        "sentiment = model.predict([check][0])[0][0]\n",
        "if sentiment>=0.5:\n",
        "  reviewType = \"Positive\"\n",
        "else:\n",
        "    reviewType = \"Negative\"\n",
        "    \n",
        "sentiment2 = model2.predict([check][0])[0][0]\n",
        "if sentiment2>=0.5:\n",
        "  reviewType2 = \"Positive\"\n",
        "else:\n",
        "    reviewType2 = \"Negative\"\n",
        "    \n",
        "print(\"Model 1(MLP) Result : Sentiment: %s ; Review Type: %s Review\" % (sentiment, reviewType))\n",
        "print(\"Model 2(LSTM) Result : Sentiment: %s ; Review Type: %s Review\" % (sentiment2, reviewType2))\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 1(MLP) Result : Sentiment: 0.21340767 ; Review Type: Negative Review\n",
            "Model 2(LSTM) Result : Sentiment: 0.45238253 ; Review Type: Negative Review\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a2FbJjrncwur",
        "colab_type": "code",
        "outputId": "78853d5f-9ae5-4772-c86e-7b62ed1a9f0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#short positive review\n",
        "review=\"I really liked the movie and had fun\"\n",
        "\n",
        "tmp=[]\n",
        "word_to_id = keras.datasets.imdb.get_word_index()\n",
        "\n",
        "review = review.lower()\n",
        "review = review.replace('.', '')\n",
        "\n",
        "\n",
        "for word in review.split(\" \"):\n",
        "  try:\n",
        "    (word_to_id[word])\n",
        "    tmp.append(word_to_id[word])\n",
        "  except:\n",
        "    tmp.append(0)\n",
        "    \n",
        "check = keras.preprocessing.sequence.pad_sequences([tmp],\n",
        "                                                        maxlen=max_len)\n",
        "\n",
        "sentiment = model.predict([check][0])[0][0]\n",
        "if sentiment>=0.5:\n",
        "  reviewType = \"Positive\"\n",
        "else:\n",
        "    reviewType = \"Negative\"\n",
        "    \n",
        "sentiment2 = model2.predict([check][0])[0][0]\n",
        "if sentiment2>=0.5:\n",
        "  reviewType2 = \"Positive\"\n",
        "else:\n",
        "    reviewType2 = \"Negative\"\n",
        "    \n",
        "print(\"Model 1(MLP) Result : Sentiment: %s ; Review Type: %s Review\" % (sentiment, reviewType))\n",
        "print(\"Model 2(LSTM) Result : Sentiment: %s ; Review Type: %s Review\" % (sentiment2, reviewType2))\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 1(MLP) Result : Sentiment: 0.2090727 ; Review Type: Negative Review\n",
            "Model 2(LSTM) Result : Sentiment: 0.71501875 ; Review Type: Positive Review\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DtnoIXbkJvEg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2b0744a5-c3ad-4dc0-e3b2-1bbb469fae19"
      },
      "cell_type": "code",
      "source": [
        "#long good review\n",
        "review = \"The plot is very much in foot-on-the-pedal motion all the way through, without so much as a stop for breath. There are so many major, future-of-the-MCU-altering moments throughout that you might event forget some of the early big moments by the time you’re halfway through. All you really need to know before going in is that Thanos is on the way, and as he has crossed paths in some tangential ways with many of our MCU heroes prior to this, they’re all going to be drawn into his orbit. As his masterplan involves grand-scale annihilation, it’s going to take the biggest team-up yet to stop him. So as well as core Avengers like Stark, Thor (Chris Hemsworth), Captain America (Chris Evans), Black Widow (Scarlett Johansson), and Bruce Banner (Mark Ruffalo), more recent players such as Black Panther (Chadwick Boseman), Doctor Strange (Benedict Cumberbatch), Spidey (Tom Holland), and the Guardians are also thrown into the mix.But, this time, far from being a mere cameo-er, Thanos’ is the throughline of the movie, the protagonist, if Infinity War can be considered to have one. CGI baddies with evil schemes have been the downfall of many superhero movies, but thankfully Josh Brolin’s hulking purple bruiser is no let down. As a piece of visual wizardry, he’s impressively textured and hefty, but more impressive is still is that there’s Brolin nuance underneath the pixels (that grin), and that while he might not reach Killmonger levels of sympathy, his plan does have shades of plausibility that prevent him from slipping into OTT maniacal-laugh territory. His scenes involving Gamora (Zoe Saldana) are his strongest, and they also provide a showcase for the Guardians’ green warrior to do some of her best emoting of the series.By necessity, no good guy gets a particularly huge amount of screentime here. As is inevitable with a movie like this, individual characters (besides Thanos) get cool moments rather than any real depth, but that’s part and parcel with this extended universe: your engagement will be highly dependent on how invested you’ve been thus far. Some heroes get more to do than others (if Thor gets a decent amount of screentime, Black Widow feels particularly short-changed), but ultimately, it’s a team effort in every sense.The heroes are mostly defined instead by their interactions with each other. Sparks fly between Stark and Strange, and Thor and the Guardians, to pleasing effect: the two goateed geniuses are frequently at loggerheads, and Star-Lord (Chris Pratt) is somewhat put out by Thor’s arrival on board the Milano, and the Asgardian has a winning repartee with Rocket Raccoon. Given minimal screentime, Elizabeth Olsen and Paul Bettany make the Scarlet Witch/Vision relationship convince. Oh, and Tom Holland continues to prove he’s the best screen Spidey yet, furthering his relationship with reluctant mentor Stark in the process. And – as the trailers have revealed – a key part of the climax takes place in Wakanda, and it’s a thrill to be back here so soon after Black Panther. Again, these characters and their relationships will mean less for newcomers, but for the committed fan there’s barely a beat that goes by without inducing giggles and/or dropping jaws.Despite the heavy, genocidal subject matter, there’s plenty of the MCU’s trademark humour, most of it delivered by the on-form Guardians, stealing pretty much every scene they’re in, and somehow managing to retain their unique tone even within this Avengers mix. And as well as the humour, there are moments of genuine emotion that you rarely get in this kind of tentpole movie (once again, that’s down to that accumulated investment). It reaches its highest moments when throwing together unusual combos of characters: in action sequences, odd-couple banter, and high-stakes emotional interactions. And its all set against a background of legitimate peril, as Thanos sets about retrieving the Infinity Stones he needs to enact his plan.Credit is of course due to directors the Russo brothers for pulling together something of this scale and ambition with such clarity and confidence. Having Thanos driving the narrative helps. The Infinity Stones have always felt like McGuffins, and even if their use and provenance isn’t always all that obvious, they’re a simple ploy for ratcheting tension: the more of the coloured gems that Thanos shoves into his golden gauntlet, the worse things get for future of life on Earth (and other planets). Even if you haven’t entirely kept up with the whereabout of the stones to this point, you’ll fare just fine. The action scenes are also delivered with flair and crunch: and as ever, the best involve characters working in unison and combining their powers in special moves. Crucially, you can always tell what’s going on in big fight scenes, and you never lose sight of the characters.\"\n",
        "tmp=[]\n",
        "word_to_id = keras.datasets.imdb.get_word_index()\n",
        "\n",
        "review = review.lower()\n",
        "review = review.replace('.', '')\n",
        "\n",
        "for word in review.split(\" \"):\n",
        "  try:\n",
        "    (word_to_id[word])\n",
        "    tmp.append(word_to_id[word])\n",
        "  except:\n",
        "    tmp.append(0)\n",
        "    \n",
        "check = keras.preprocessing.sequence.pad_sequences([tmp],\n",
        "                                                        maxlen=max_len)\n",
        "\n",
        "sentiment = model.predict([check][0])[0][0]\n",
        "if sentiment>=0.5:\n",
        "  reviewType = \"Positive\"\n",
        "else:\n",
        "    reviewType = \"Negative\"\n",
        "    \n",
        "sentiment2 = model2.predict([check][0])[0][0]\n",
        "if sentiment2>=0.5:\n",
        "  reviewType2 = \"Positive\"\n",
        "else:\n",
        "    reviewType2 = \"Negative\"\n",
        "    \n",
        "print(\"Model 1(MLP) Result : Sentiment: %s ; Review Type: %s Review\" % (sentiment, reviewType))\n",
        "print(\"Model 2(LSTM) Result : Sentiment: %s ; Review Type: %s Review\" % (sentiment2, reviewType2))\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 1(MLP) Result : Sentiment: 0.7421498 ; Review Type: Positive Review\n",
            "Model 2(LSTM) Result : Sentiment: 0.5721965 ; Review Type: Positive Review\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zbk1Um_UK5Xn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7aab5deb-8244-449e-8476-86667e135043"
      },
      "cell_type": "code",
      "source": [
        "#long bad review\n",
        "review=\"A predictable slog disguised as a family-friendly talking-animal movie, this Barry Sonnenfeld film wastes its award winning cast for a bunch of kitty litter jokes. Nine Lives is the kind of kid targeted comedy that makes audiences wonder what the stars wanted to buy with their salary or who they owed a favor. The fundamental flaw is that, unlike most live action movies featuring animals that talk amongst themselves, in this one, only the audience and Walken's character can hear Mr. Fuzzypants speak as Spacey. And the dad as kitty monologues and one liners aren't at all funny or original (although kids might laugh at every third or fourth cat slapstick sequence).Garner who rose to fame as a powerful covert agent assassin on Alias once again plays a mom dealing with family issues, which is disappointing she can do a lot more than boring mom roles. Cheryl Hines appears as Tom's always ready for a cocktail ex-wife, Madison, who is (implausibly) good friends with Lara. Amell's presence as Tom's oldest son and employee underscores what a jerk Tom is to his kids, but that's basically the entire premise of this yawn-worthy story Workaholic dad learns to make time for his kids after spending time with a cat.\"\n",
        "\n",
        "tmp=[]\n",
        "word_to_id = keras.datasets.imdb.get_word_index()\n",
        "\n",
        "review = review.lower()\n",
        "review = review.replace('.', '')\n",
        "\n",
        "for word in review.split(\" \"):\n",
        "  try:\n",
        "    (word_to_id[word])\n",
        "    tmp.append(word_to_id[word])\n",
        "  except:\n",
        "    tmp.append(0)\n",
        "    \n",
        "check = keras.preprocessing.sequence.pad_sequences([tmp],\n",
        "                                                        maxlen=max_len)\n",
        "\n",
        "sentiment = model.predict([check][0])[0][0]\n",
        "if sentiment>=0.5:\n",
        "  reviewType = \"Positive\"\n",
        "else:\n",
        "    reviewType = \"Negative\"\n",
        "    \n",
        "sentiment2 = model2.predict([check][0])[0][0]\n",
        "if sentiment2>=0.5:\n",
        "  reviewType2 = \"Positive\"\n",
        "else:\n",
        "    reviewType2 = \"Negative\"\n",
        "    \n",
        "print(\"Model 1(MLP) Result : Sentiment: %s ; Review Type: %s Review\" % (sentiment, reviewType))\n",
        "print(\"Model 2(LSTM) Result : Sentiment: %s ; Review Type: %s Review\" % (sentiment2, reviewType2))\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 1(MLP) Result : Sentiment: 0.016271133 ; Review Type: Negative Review\n",
            "Model 2(LSTM) Result : Sentiment: 0.019543588 ; Review Type: Negative Review\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}